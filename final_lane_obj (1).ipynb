{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX9BZvANzuUC",
        "outputId": "5767f4ce-f8fa-4914-b268-536e36cd26a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Dt-Pham/Advanced-Lane-Lines.git\n",
        "%cd Advanced-Lane-Lines/\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "import cv2 # Import the OpenCV library to enable computer vision\n",
        "import numpy as np # Import the NumPy scientific computing library\n",
        "import matplotlib.image as mpimg\n",
        "from docopt import docopt\n",
        "from IPython.display import HTML\n",
        "from IPython.core.display import Video\n",
        "from moviepy.editor import VideoFileClip\n",
        "from CameraCalibration import CameraCalibration\n",
        "from Thresholding import *\n",
        "from PerspectiveTransformation import *\n",
        "from LaneLines import *\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqch5Mtgz0x9",
        "outputId": "87aa00e1-f3f1-4409-8bdf-4a6b82aeb912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Advanced-Lane-Lines' already exists and is not an empty directory.\n",
            "/content/Advanced-Lane-Lines\n",
            "torch:  1.10 ; cuda:  cu111\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
            "Requirement already satisfied: detectron2 in /usr/local/lib/python3.7/dist-packages (0.6+cu111)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (21.4b2)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.1)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.8)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.63.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.1.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.8.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.5.post20220305)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (2022.3.15)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.4.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
            "Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.9.0)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n",
            "Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (6.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (4.8)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.7.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.11.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implemented Object Detection and Lane Detection on frames of a video(Kitti visual odometry dataset)**\n",
        "\n",
        "The training of Object detection model was done using tranfer learning, on facebook's detectron2 model.\n"
      ],
      "metadata": {
        "id": "OuLMA02AsnUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#final model\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from google.colab.patches import cv2_imshow\n",
        "#import cv2 # Import the OpenCV library to enable computer vision\n",
        "import numpy as np # Import the NumPy scientific computing library\n",
        "import edge_detection as edge # Handles the detection of lane lines\n",
        "import matplotlib.pyplot as plt # Used for plotting and error checking\n",
        "import cv2 # Import the OpenCV library to enable computer vision\n",
        "import numpy as np # Import the NumPy scientific computing library\n",
        "import matplotlib.image as mpimg\n",
        "from docopt import docopt\n",
        "from IPython.display import HTML\n",
        "from IPython.core.display import Video\n",
        "from moviepy.editor import VideoFileClip\n",
        "\"\"\"from CameraCalibration import CameraCalibration\n",
        "from Thresholding import *\n",
        "from PerspectiveTransformation import *\n",
        "from LaneLines import *\"\"\"\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "# Author: Addison Sears-Collins\n",
        "# https://automaticaddison.com\n",
        "# Description: Implementation of the Lane class\n",
        "\n",
        "class Lane:\n",
        "  \"\"\"\n",
        "  Represents a lane on a road.\n",
        "  \"\"\"\n",
        "  def __init__(self, orig_frame):\n",
        "    \"\"\"\n",
        "      Default constructor\n",
        "\n",
        "    :param orig_frame: Original camera image (i.e. frame)\n",
        "    \"\"\"\n",
        "    try:\n",
        "\n",
        "      self.orig_frame = orig_frame\n",
        "\n",
        "      # This will hold an image with the lane lines\n",
        "      self.lane_line_markings = None\n",
        "\n",
        "      # This will hold the image after perspective transformation\n",
        "      self.warped_frame = None\n",
        "      self.transformation_matrix = None\n",
        "      self.inv_transformation_matrix = None\n",
        "\n",
        "      # (Width, Height) of the original video frame (or image)\n",
        "      self.orig_image_size = self.orig_frame.shape[::-1][1:]\n",
        "\n",
        "      width = self.orig_image_size[0]\n",
        "      height = self.orig_image_size[1]\n",
        "      self.width = width\n",
        "      self.height = height\n",
        "\n",
        "      # Four corners of the trapezoid-shaped region of interest\n",
        "      # You need to find these corners manually.\n",
        "      self.roi_points = np.float32([\n",
        "        (440,230), # Top-left corner\n",
        "        (170, 360), # Bottom-left corner\n",
        "        (700,335), # Bottom-right corner\n",
        "        (630,230) # Top-right corner\n",
        "      ])\n",
        "\n",
        "      # The desired corner locations  of the region of interest\n",
        "      # after we perform perspective transformation.\n",
        "      # Assume image width of 600, padding == 150.\n",
        "      self.padding = int(0.25 * width) # padding from side of the image in pixels\n",
        "      self.desired_roi_points = np.float32([\n",
        "        [self.padding, 0], # Top-left corner\n",
        "        [self.padding, self.orig_image_size[1]], # Bottom-left corner\n",
        "        [self.orig_image_size[\n",
        "          0]-self.padding, self.orig_image_size[1]], # Bottom-right corner\n",
        "        [self.orig_image_size[0]-self.padding, 0] # Top-right corner\n",
        "      ])\n",
        "\n",
        "      # Histogram that shows the white pixel peaks for lane line detection\n",
        "      self.histogram = None\n",
        "\n",
        "      # Sliding window parameters\n",
        "      self.no_of_windows = 10\n",
        "      self.margin = int((1/12) * width)  # Window width is +/- margin\n",
        "      self.minpix = int((1/24) * width)  # Min no. of pixels to recenter window\n",
        "\n",
        "      # Best fit polynomial lines for left line and right line of the lane\n",
        "      self.left_fit = None\n",
        "      self.right_fit = None\n",
        "      self.left_lane_inds = None\n",
        "      self.right_lane_inds = None\n",
        "      self.ploty = None\n",
        "      self.left_fitx = None\n",
        "      self.right_fitx = None\n",
        "      self.leftx = None\n",
        "      self.rightx = None\n",
        "      self.lefty = None\n",
        "      self.righty = None\n",
        "\n",
        "      # Pixel parameters for x and y dimensions\n",
        "      self.YM_PER_PIX = 10.0 / 1000 # meters per pixel in y dimension\n",
        "      self.XM_PER_PIX = 3.7 / 781 # meters per pixel in x dimension\n",
        "\n",
        "      # Radii of curvature and offset\n",
        "      self.left_curvem = None\n",
        "      self.right_curvem = None\n",
        "      self.center_offset = None\n",
        "    except:\n",
        "      pass\n",
        "  def calculate_car_position(self, print_to_terminal=False):\n",
        "    try:\n",
        "\n",
        "      \"\"\"\n",
        "      Calculate the position of the car relative to the center\n",
        "\n",
        "      :param: print_to_terminal Display data to console if True\n",
        "      :return: Offset from the center of the lane\n",
        "      \"\"\"\n",
        "      # Assume the camera is centered in the image.\n",
        "      # Get position of car in centimeters\n",
        "      car_location = self.orig_frame.shape[1] / 2\n",
        "\n",
        "      # Fine the x coordinate of the lane line bottom\n",
        "      height = self.orig_frame.shape[0]\n",
        "      bottom_left = self.left_fit[0]*height**2 + self.left_fit[\n",
        "        1]*height + self.left_fit[2]\n",
        "      bottom_right = self.right_fit[0]*height**2 + self.right_fit[\n",
        "        1]*height + self.right_fit[2]\n",
        "\n",
        "      center_lane = (bottom_right - bottom_left)/2 + bottom_left\n",
        "      center_offset = (np.abs(car_location) - np.abs(\n",
        "        center_lane)) * self.XM_PER_PIX * 100\n",
        "\n",
        "      if print_to_terminal == True:\n",
        "        print(str(center_offset) + 'cm')\n",
        "\n",
        "      self.center_offset = center_offset\n",
        "\n",
        "      return center_offset\n",
        "    except:\n",
        "      pass\n",
        "  def calculate_curvature(self, print_to_terminal=False):\n",
        "    try:\n",
        "      \"\"\"\n",
        "      Calculate the road curvature in meters.\n",
        "\n",
        "      :param: print_to_terminal Display data to console if True\n",
        "      :return: Radii of curvature\n",
        "      \"\"\"\n",
        "      # Set the y-value where we want to calculate the road curvature.\n",
        "      # Select the maximum y-value, which is the bottom of the frame.\n",
        "      y_eval = np.max(self.ploty)\n",
        "\n",
        "      # Fit polynomial curves to the real world environment\n",
        "      left_fit_cr = np.polyfit(self.lefty * self.YM_PER_PIX, self.leftx * (\n",
        "        self.XM_PER_PIX), 2)\n",
        "      right_fit_cr = np.polyfit(self.righty * self.YM_PER_PIX, self.rightx * (\n",
        "        self.XM_PER_PIX), 2)\n",
        "\n",
        "      # Calculate the radii of curvature\n",
        "      left_curvem = ((1 + (2*left_fit_cr[0]*y_eval*self.YM_PER_PIX + left_fit_cr[\n",
        "                      1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
        "      right_curvem = ((1 + (2*right_fit_cr[\n",
        "                      0]*y_eval*self.YM_PER_PIX + right_fit_cr[\n",
        "                      1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
        "\n",
        "      # Display on terminal window\n",
        "      if print_to_terminal == True:\n",
        "        print(left_curvem, 'm', right_curvem, 'm')\n",
        "\n",
        "      self.left_curvem = left_curvem\n",
        "      self.right_curvem = right_curvem\n",
        "\n",
        "      return left_curvem, right_curvem\n",
        "    except:\n",
        "      pass\n",
        "  def calculate_histogram(self,frame=None,plot=True):\n",
        "    try:\n",
        "      \"\"\"\n",
        "      Calculate the image histogram to find peaks in white pixel count\n",
        "\n",
        "      :param frame: The warped image\n",
        "      :param plot: Create a plot if True\n",
        "      \"\"\"\n",
        "      if frame is None:\n",
        "        frame = self.warped_frame\n",
        "\n",
        "      # Generate the histogram\n",
        "      self.histogram = np.sum(frame[int(\n",
        "                frame.shape[0]/2):,:], axis=0)\n",
        "\n",
        "      if plot == True:\n",
        "\n",
        "        # Draw both the image and the histogram\n",
        "        figure, (ax1, ax2) = plt.subplots(2,1) # 2 row, 1 columns\n",
        "        figure.set_size_inches(10, 5)\n",
        "        ax1.imshow(frame, cmap='gray')\n",
        "        ax1.set_title(\"Warped Binary Frame\")\n",
        "        ax2.plot(self.histogram)\n",
        "        ax2.set_title(\"Histogram Peaks\")\n",
        "        plt.show()\n",
        "\n",
        "      return self.histogram\n",
        "    except:\n",
        "      pass\n",
        "  def display_curvature_offset(self, frame=None, plot=False):\n",
        "    try:\n",
        "      \"\"\"\n",
        "      Display curvature and offset statistics on the image\n",
        "\n",
        "      :param: plot Display the plot if True\n",
        "      :return: Image with lane lines and curvature\n",
        "      \"\"\"\n",
        "      image_copy = None\n",
        "      if frame is None:\n",
        "        image_copy = self.orig_frame.copy()\n",
        "      else:\n",
        "        image_copy = frame\n",
        "\n",
        "      cv2.putText(image_copy,'Curve Radius: '+str((\n",
        "        self.left_curvem+self.right_curvem)/2)[:7]+' m', (int((\n",
        "        5/600)*self.width), int((\n",
        "        20/338)*self.height)), cv2.FONT_HERSHEY_SIMPLEX, (float((\n",
        "        0.5/600)*self.width)),(\n",
        "        255,255,255),2,cv2.LINE_AA)\n",
        "      cv2.putText(image_copy,'Center Offset: '+str(\n",
        "        self.center_offset)[:7]+' cm', (int((\n",
        "        5/600)*self.width), int((\n",
        "        40/338)*self.height)), cv2.FONT_HERSHEY_SIMPLEX, (float((\n",
        "        0.5/600)*self.width)),(\n",
        "        255,255,255),2,cv2.LINE_AA)\n",
        "\n",
        "      \"\"\"    if plot==True:\n",
        "            #cv2.imshow(\"Image with Curvature and Offset\", image_copy)\n",
        "\n",
        "          return image_copy\"\"\"\n",
        "    except:\n",
        "      pass\n",
        "  def get_lane_line_previous_window(self, left_fit, right_fit, plot=False):\n",
        "    try:\n",
        "      \"\"\"\n",
        "      Use the lane line from the previous sliding window to get the parameters\n",
        "      for the polynomial line for filling in the lane line\n",
        "      :param: left_fit Polynomial function of the left lane line\n",
        "      :param: right_fit Polynomial function of the right lane line\n",
        "      :param: plot To display an image or not\n",
        "      \"\"\"\n",
        "      # margin is a sliding window parameter\n",
        "      margin = self.margin\n",
        "\n",
        "      # Find the x and y coordinates of all the nonzero\n",
        "      # (i.e. white) pixels in the frame.\n",
        "      nonzero = self.warped_frame.nonzero()\n",
        "      nonzeroy = np.array(nonzero[0])\n",
        "      nonzerox = np.array(nonzero[1])\n",
        "\n",
        "      # Store left and right lane pixel indices\n",
        "      left_lane_inds = ((nonzerox > (left_fit[0]*(\n",
        "        nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (\n",
        "        nonzerox < (left_fit[0]*(\n",
        "        nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
        "      right_lane_inds = ((nonzerox > (right_fit[0]*(\n",
        "        nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (\n",
        "        nonzerox < (right_fit[0]*(\n",
        "        nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
        "      self.left_lane_inds = left_lane_inds\n",
        "      self.right_lane_inds = right_lane_inds\n",
        "\n",
        "      # Get the left and right lane line pixel locations\n",
        "      leftx = nonzerox[left_lane_inds]\n",
        "      lefty = nonzeroy[left_lane_inds]\n",
        "      rightx = nonzerox[right_lane_inds]\n",
        "      righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "      self.leftx = leftx\n",
        "      self.rightx = rightx\n",
        "      self.lefty = lefty\n",
        "      self.righty = righty\n",
        "\n",
        "      # Fit a second order polynomial curve to each lane line\n",
        "      left_fit = np.polyfit(lefty, leftx, 2)\n",
        "      right_fit = np.polyfit(righty, rightx, 2)\n",
        "      self.left_fit = left_fit\n",
        "      self.right_fit = right_fit\n",
        "\n",
        "      # Create the x and y values to plot on the image\n",
        "      ploty = np.linspace(\n",
        "        0, self.warped_frame.shape[0]-1, self.warped_frame.shape[0])\n",
        "      left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
        "      right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
        "      self.ploty = ploty\n",
        "      self.left_fitx = left_fitx\n",
        "      self.right_fitx = right_fitx\n",
        "\n",
        "      if plot==True:\n",
        "\n",
        "        # Generate images to draw on\n",
        "        out_img = np.dstack((self.warped_frame, self.warped_frame, (\n",
        "                            self.warped_frame)))*255\n",
        "        window_img = np.zeros_like(out_img)\n",
        "\n",
        "        # Add color to the left and right line pixels\n",
        "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
        "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [\n",
        "                                                                      0, 0, 255]\n",
        "        # Create a polygon to show the search window area, and recast\n",
        "        # the x and y points into a usable format for cv2.fillPoly()\n",
        "        margin = self.margin\n",
        "        left_line_window1 = np.array([np.transpose(np.vstack([\n",
        "                                      left_fitx-margin, ploty]))])\n",
        "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([\n",
        "                                      left_fitx+margin, ploty])))])\n",
        "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
        "        right_line_window1 = np.array([np.transpose(np.vstack([\n",
        "                                      right_fitx-margin, ploty]))])\n",
        "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([\n",
        "                                      right_fitx+margin, ploty])))])\n",
        "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
        "\n",
        "        # Draw the lane onto the warped blank image\n",
        "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
        "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
        "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
        "\n",
        "        # Plot the figures\n",
        "        figure, (ax1, ax2, ax3) = plt.subplots(3,1) # 3 rows, 1 column\n",
        "        figure.set_size_inches(10, 10)\n",
        "        figure.tight_layout(pad=3.0)\n",
        "        ax1.imshow(cv2.cvtColor(self.orig_frame, cv2.COLOR_BGR2RGB))\n",
        "        ax2.imshow(self.warped_frame, cmap='gray')\n",
        "        ax3.imshow(result)\n",
        "        ax3.plot(left_fitx, ploty, color='yellow')\n",
        "        ax3.plot(right_fitx, ploty, color='yellow')\n",
        "        ax1.set_title(\"Original Frame\")\n",
        "        ax2.set_title(\"Warped Frame\")\n",
        "        ax3.set_title(\"Warped Frame With Search Window\")\n",
        "        plt.show()\n",
        "    except:\n",
        "      pass\n",
        "  def get_lane_line_indices_sliding_windows(self, plot=False):\n",
        "    \"\"\"\n",
        "    Get the indices of the lane line pixels using the\n",
        "    sliding windows technique.\n",
        "\n",
        "    :param: plot Show plot or not\n",
        "    :return: Best fit lines for the left and right lines of the current lane\n",
        "    \"\"\"\n",
        "    try:\n",
        "      # Sliding window width is +/- margin\n",
        "      margin = self.margin\n",
        "\n",
        "      frame_sliding_window = self.warped_frame.copy()\n",
        "\n",
        "      # Set the height of the sliding windows\n",
        "      window_height = np.int(self.warped_frame.shape[0]/self.no_of_windows)\n",
        "\n",
        "      # Find the x and y coordinates of all the nonzero\n",
        "      # (i.e. white) pixels in the frame.\n",
        "      nonzero = self.warped_frame.nonzero()\n",
        "      nonzeroy = np.array(nonzero[0])\n",
        "      nonzerox = np.array(nonzero[1])\n",
        "\n",
        "      # Store the pixel indices for the left and right lane lines\n",
        "      left_lane_inds = []\n",
        "      right_lane_inds = []\n",
        "\n",
        "      # Current positions for pixel indices for each window,\n",
        "      # which we will continue to update\n",
        "      leftx_base, rightx_base = self.histogram_peak()\n",
        "      leftx_current = leftx_base\n",
        "      rightx_current = rightx_base\n",
        "\n",
        "      # Go through one window at a time\n",
        "      no_of_windows = self.no_of_windows\n",
        "\n",
        "      for window in range(no_of_windows):\n",
        "\n",
        "        # Identify window boundaries in x and y (and right and left)\n",
        "        win_y_low = self.warped_frame.shape[0] - (window + 1) * window_height\n",
        "        win_y_high = self.warped_frame.shape[0] - window * window_height\n",
        "        win_xleft_low = leftx_current - margin\n",
        "        win_xleft_high = leftx_current + margin\n",
        "        win_xright_low = rightx_current - margin\n",
        "        win_xright_high = rightx_current + margin\n",
        "        cv2.rectangle(frame_sliding_window,(win_xleft_low,win_y_low),(\n",
        "          win_xleft_high,win_y_high), (255,255,255), 2)\n",
        "        cv2.rectangle(frame_sliding_window,(win_xright_low,win_y_low),(\n",
        "          win_xright_high,win_y_high), (255,255,255), 2)\n",
        "\n",
        "        # Identify the nonzero pixels in x and y within the window\n",
        "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                            (nonzerox >= win_xleft_low) & (\n",
        "                            nonzerox < win_xleft_high)).nonzero()[0]\n",
        "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                            (nonzerox >= win_xright_low) & (\n",
        "                              nonzerox < win_xright_high)).nonzero()[0]\n",
        "\n",
        "        # Append these indices to the lists\n",
        "        left_lane_inds.append(good_left_inds)\n",
        "        right_lane_inds.append(good_right_inds)\n",
        "\n",
        "        # If you found > minpix pixels, recenter next window on mean position\n",
        "        minpix = self.minpix\n",
        "        if len(good_left_inds) > minpix:\n",
        "          leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
        "        if len(good_right_inds) > minpix:\n",
        "          rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
        "\n",
        "      # Concatenate the arrays of indices\n",
        "      left_lane_inds = np.concatenate(left_lane_inds)\n",
        "      right_lane_inds = np.concatenate(right_lane_inds)\n",
        "\n",
        "      # Extract the pixel coordinates for the left and right lane lines\n",
        "      leftx = nonzerox[left_lane_inds]\n",
        "      lefty = nonzeroy[left_lane_inds]\n",
        "      rightx = nonzerox[right_lane_inds]\n",
        "      righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "      # Fit a second order polynomial curve to the pixel coordinates for\n",
        "      # the left and right lane lines\n",
        "      left_fit = np.polyfit(lefty, leftx, 2)\n",
        "      right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "      self.left_fit = left_fit\n",
        "      self.right_fit = right_fit\n",
        "\n",
        "      if plot==True:\n",
        "\n",
        "        # Create the x and y values to plot on the image\n",
        "        ploty = np.linspace(\n",
        "          0, frame_sliding_window.shape[0]-1, frame_sliding_window.shape[0])\n",
        "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
        "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
        "\n",
        "        # Generate an image to visualize the result\n",
        "        out_img = np.dstack((\n",
        "          frame_sliding_window, frame_sliding_window, (\n",
        "          frame_sliding_window))) * 255\n",
        "\n",
        "        # Add color to the left line pixels and right line pixels\n",
        "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
        "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [\n",
        "          0, 0, 255]\n",
        "\n",
        "        # Plot the figure with the sliding windows\n",
        "        figure, (ax1, ax2, ax3) = plt.subplots(3,1) # 3 rows, 1 column\n",
        "        figure.set_size_inches(10, 10)\n",
        "        figure.tight_layout(pad=3.0)\n",
        "        ax1.imshow(cv2.cvtColor(self.orig_frame, cv2.COLOR_BGR2RGB))\n",
        "        ax2.imshow(frame_sliding_window, cmap='gray')\n",
        "        ax3.imshow(out_img)\n",
        "        ax3.plot(left_fitx, ploty, color='yellow')\n",
        "        ax3.plot(right_fitx, ploty, color='yellow')\n",
        "        ax1.set_title(\"Original Frame\")\n",
        "        ax2.set_title(\"Warped Frame with Sliding Windows\")\n",
        "        ax3.set_title(\"Detected Lane Lines with Sliding Windows\")\n",
        "        plt.show()\n",
        "\n",
        "      return self.left_fit, self.right_fit\n",
        "    except:\n",
        "      pass\n",
        "  def get_line_markings(self, frame=None):\n",
        "    \"\"\"\n",
        "    Isolates lane lines.\n",
        "\n",
        "      :param frame: The camera frame that contains the lanes we want to detect\n",
        "    :return: Binary (i.e. black and white) image containing the lane lines.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      if frame is None:\n",
        "        frame = self.orig_frame\n",
        "\n",
        "      # Convert the video frame from BGR (blue, green, red)\n",
        "      # color space to HLS (hue, saturation, lightness).\n",
        "      hls = cv2.cvtColor(frame, cv2.COLOR_BGR2HLS)\n",
        "\n",
        "      ################### Isolate possible lane line edges ######################\n",
        "\n",
        "      # Perform Sobel edge detection on the L (lightness) channel of\n",
        "      # the image to detect sharp discontinuities in the pixel intensities\n",
        "      # along the x and y axis of the video frame.\n",
        "      # sxbinary is a matrix full of 0s (black) and 255 (white) intensity values\n",
        "      # Relatively light pixels get made white. Dark pixels get made black.\n",
        "      _, sxbinary = edge.threshold(hls[:, :, 1], thresh=(120, 255))\n",
        "      sxbinary = edge.blur_gaussian(sxbinary, ksize=3) # Reduce noise\n",
        "\n",
        "      # 1s will be in the cells with the highest Sobel derivative values\n",
        "      # (i.e. strongest lane line edges)\n",
        "      sxbinary = edge.mag_thresh(sxbinary, sobel_kernel=3, thresh=(110, 255))\n",
        "\n",
        "      ######################## Isolate possible lane lines ######################\n",
        "\n",
        "      # Perform binary thresholding on the S (saturation) channel\n",
        "      # of the video frame. A high saturation value means the hue color is pure.\n",
        "      # We expect lane lines to be nice, pure colors (i.e. solid white, yellow)\n",
        "      # and have high saturation channel values.\n",
        "      # s_binary is matrix full of 0s (black) and 255 (white) intensity values\n",
        "      # White in the regions with the purest hue colors (e.g. >80...play with\n",
        "      # this value for best results).\n",
        "      s_channel = hls[:, :, 2] # use only the saturation channel data\n",
        "      _, s_binary = edge.threshold(s_channel, (80, 255))\n",
        "\n",
        "      # Perform binary thresholding on the R (red) channel of the\n",
        "          # original BGR video frame.\n",
        "      # r_thresh is a matrix full of 0s (black) and 255 (white) intensity values\n",
        "      # White in the regions with the richest red channel values (e.g. >120).\n",
        "      # Remember, pure white is bgr(255, 255, 255).\n",
        "      # Pure yellow is bgr(0, 255, 255). Both have high red channel values.\n",
        "      _, r_thresh = edge.threshold(frame[:, :, 2], thresh=(120, 255))\n",
        "\n",
        "      # Lane lines should be pure in color and have high red channel values\n",
        "      # Bitwise AND operation to reduce noise and black-out any pixels that\n",
        "      # don't appear to be nice, pure, solid colors (like white or yellow lane\n",
        "      # lines.)\n",
        "      rs_binary = cv2.bitwise_and(s_binary, r_thresh)\n",
        "\n",
        "      ### Combine the possible lane lines with the possible lane line edges #####\n",
        "      # If you show rs_binary visually, you'll see that it is not that different\n",
        "      # from this return value. The edges of lane lines are thin lines of pixels.\n",
        "      self.lane_line_markings = cv2.bitwise_or(rs_binary, sxbinary.astype(\n",
        "                                np.uint8))\n",
        "      return self.lane_line_markings\n",
        "    except:\n",
        "      pass\n",
        "  def histogram_peak(self):\n",
        "    \"\"\"\n",
        "    Get the left and right peak of the histogram\n",
        "\n",
        "    Return the x coordinate of the left histogram peak and the right histogram\n",
        "    peak.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      midpoint = np.int(self.histogram.shape[0]/2)\n",
        "      leftx_base = np.argmax(self.histogram[:midpoint])\n",
        "      rightx_base = np.argmax(self.histogram[midpoint:]) + midpoint\n",
        "\n",
        "      # (x coordinate of left peak, x coordinate of right peak)\n",
        "      return leftx_base, rightx_base\n",
        "    except:\n",
        "      pass\n",
        "  def overlay_lane_lines(self, plot=False):\n",
        "    \"\"\"\n",
        "    Overlay lane lines on the original frame\n",
        "    :param: Plot the lane lines if True\n",
        "    :return: Lane with overlay\n",
        "    \"\"\"\n",
        "    try:\n",
        "      # Generate an image to draw the lane lines on\n",
        "      warp_zero = np.zeros_like(self.warped_frame).astype(np.uint8)\n",
        "      color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
        "\n",
        "      # Recast the x and y points into usable format for cv2.fillPoly()\n",
        "      pts_left = np.array([np.transpose(np.vstack([\n",
        "                          self.left_fitx, self.ploty]))])\n",
        "      pts_right = np.array([np.flipud(np.transpose(np.vstack([\n",
        "                            self.right_fitx, self.ploty])))])\n",
        "      pts = np.hstack((pts_left, pts_right))\n",
        "\n",
        "      # Draw lane on the warped blank image\n",
        "      cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
        "\n",
        "      # Warp the blank back to original image space using inverse perspective\n",
        "      # matrix (Minv)\n",
        "      newwarp = cv2.warpPerspective(color_warp, self.inv_transformation_matrix, (\n",
        "                                    self.orig_frame.shape[\n",
        "                                    1], self.orig_frame.shape[0]))\n",
        "\n",
        "      # Combine the result with the original image\n",
        "      result = cv2.addWeighted(self.orig_frame, 1, newwarp, 0.3, 0)\n",
        "\n",
        "      if plot==True:\n",
        "\n",
        "        # Plot the figures\n",
        "        figure, (ax1, ax2) = plt.subplots(2,1) # 2 rows, 1 column\n",
        "        figure.set_size_inches(10, 10)\n",
        "        figure.tight_layout(pad=3.0)\n",
        "        ax1.imshow(cv2.cvtColor(self.orig_frame, cv2.COLOR_BGR2RGB))\n",
        "        ax2.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "        ax1.set_title(\"Original Frame\")\n",
        "        ax2.set_title(\"Original Frame With Lane Overlay\")\n",
        "        plt.show()\n",
        "\n",
        "      return result\n",
        "    except:\n",
        "      pass\n",
        "  def perspective_transform(self, frame=None, plot=False):\n",
        "    try:\n",
        "      \"\"\"\n",
        "      Perform the perspective transform.\n",
        "      :param: frame Current frame\n",
        "      :param: plot Plot the warped image if True\n",
        "      :return: Bird's eye view of the current lane\n",
        "      \"\"\"\n",
        "      if frame is None:\n",
        "        frame = self.lane_line_markings\n",
        "\n",
        "      # Calculate the transformation matrix\n",
        "      self.transformation_matrix = cv2.getPerspectiveTransform(\n",
        "        self.roi_points, self.desired_roi_points)\n",
        "\n",
        "      # Calculate the inverse transformation matrix\n",
        "      self.inv_transformation_matrix = cv2.getPerspectiveTransform(\n",
        "        self.desired_roi_points, self.roi_points)\n",
        "\n",
        "      # Perform the transform using the transformation matrix\n",
        "      self.warped_frame = cv2.warpPerspective(\n",
        "        frame, self.transformation_matrix, self.orig_image_size, flags=(\n",
        "      cv2.INTER_LINEAR))\n",
        "\n",
        "      # Convert image to binary\n",
        "      (thresh, binary_warped) = cv2.threshold(\n",
        "        self.warped_frame, 127, 255, cv2.THRESH_BINARY)\n",
        "      self.warped_frame = binary_warped\n",
        "\n",
        "      # Display the perspective transformed (i.e. warped) frame\n",
        "      if plot == True:\n",
        "        warped_copy = self.warped_frame.copy()\n",
        "        warped_plot = cv2.polylines(warped_copy, np.int32([\n",
        "                      self.desired_roi_points]), True, (147,20,255), 3)\n",
        "\n",
        "        # Display the image\n",
        "        while(1):\n",
        "          #cv2.imshow('Warped Image', warped_plot)\n",
        "\n",
        "          # Press any key to stop\n",
        "          if cv2.waitKey(0):\n",
        "            break\n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "      return self.warped_frame\n",
        "    except:\n",
        "      pass\n",
        "  def plot_roi(self, frame=None, plot=False):\n",
        "    try:\n",
        "      \"\"\"\n",
        "      Plot the region of interest on an image.\n",
        "      :param: frame The current image frame\n",
        "      :param: plot Plot the roi image if True\n",
        "      \"\"\"\n",
        "      if plot == False:\n",
        "        return\n",
        "\n",
        "      if frame is None:\n",
        "        frame = self.orig_frame.copy()\n",
        "\n",
        "      # Overlay trapezoid on the frame\n",
        "      this_image = cv2.polylines(frame, np.int32([\n",
        "        self.roi_points]), True, (147,20,255), 3)\n",
        "\n",
        "      # Display the image\n",
        "      while(1):\n",
        "        #cv2.imshow('ROI Image', this_image)\n",
        "\n",
        "        # Press any key to stop\n",
        "        if cv2.waitKey(0):\n",
        "          break\n",
        "\n",
        "      cv2.destroyAllWindows()\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "def main():\n",
        "  try:\n",
        "    # Load a frame (or image)\n",
        "    original_frame = cv2.imread(filename)\n",
        "\n",
        "    # Create a Lane object\n",
        "    lane_obj = Lane(orig_frame=original_frame)\n",
        "\n",
        "    # Perform thresholding to isolate lane lines\n",
        "    lane_line_markings = lane_obj.get_line_markings()\n",
        "\n",
        "    # Plot the region of interest on the image\n",
        "    lane_obj.plot_roi(plot=False)\n",
        "\n",
        "    # Perform the perspective transform to generate a bird's eye view\n",
        "    # If Plot == True, show image with new region of interest\n",
        "    warped_frame = lane_obj.perspective_transform(plot=False)\n",
        "\n",
        "    # Generate the image histogram to serve as a starting point\n",
        "    # for finding lane line pixels\n",
        "    histogram = lane_obj.calculate_histogram(plot=False)\n",
        "\n",
        "    # Find lane line pixels using the sliding window method\n",
        "    left_fit, right_fit = lane_obj.get_lane_line_indices_sliding_windows(\n",
        "      plot=False)\n",
        "\n",
        "    # Fill in the lane line\n",
        "    lane_obj.get_lane_line_previous_window(left_fit, right_fit, plot=False)\n",
        "\n",
        "    # Overlay lines on the original frame\n",
        "    frame_with_lane_lines = lane_obj.overlay_lane_lines(plot=True)\n",
        "\n",
        "    im = frame_with_lane_lines\n",
        "    cfg = get_cfg()\n",
        "    # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "    # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "    outputs = predictor(im)\n",
        "\n",
        "    # look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
        "    print(outputs[\"instances\"].pred_classes)\n",
        "    print(outputs[\"instances\"].pred_boxes)\n",
        "\n",
        "    # exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime\n",
        "    # Some basic setup:\n",
        "    # Setup detectron2 logger\n",
        "    # We can use `Visualizer` to draw the predictions on the image.\n",
        "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    output = cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "    # Calculate lane line curvature (left and right lane lines)\n",
        "    lane_obj.calculate_curvature(print_to_terminal=False)\n",
        "\n",
        "    # Calculate center offset\n",
        "    lane_obj.calculate_car_position(print_to_terminal=False)\n",
        "\n",
        "    # Display curvature and center offset on image\n",
        "    frame_with_lane_lines2 = lane_obj.display_curvature_offset(\n",
        "      frame=frame_with_lane_lines, plot=True)\n",
        "\n",
        "    # Create the output file name by removing the '.jpg' part\n",
        "    size = len(filename)\n",
        "    new_filename = filename[:size - 4]\n",
        "    new_filename = new_filename + '.jpg'\n",
        "\n",
        "    # Save the new image in the working directory\n",
        "    #cv2.imwrite(new_filename, lane_line_markings)\n",
        "    out.save(new_filename)\n",
        "    #cv2.imwrite(new_filename, out)\n",
        "    # Display the image\n",
        "    #cv2.imshow(\"Image\", lane_line_markings)\n",
        "\n",
        "    # Display the window until any key is pressed\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    # Close all windows\n",
        "    cv2.destroyAllWindows()\n",
        "  except:\n",
        "    pass\n",
        "folder_dir = os.listdir(\"/content/drive/MyDrive/image_3/\")\n",
        "a = []\n",
        "for i in range(len(folder_dir)):\n",
        "  #print(folder_dir[i])\n",
        "  a.append(\"/content/drive/MyDrive/image_3/\"+str(folder_dir[i]))\n",
        "  #print(a[i])\"\"\"\n",
        "  #filename = str(a[i])\n",
        "a.sort()\n",
        "b = list(a)\n",
        "print(b)\n",
        "for j in range(1,len(b)):\n",
        "  filename = str(b[j])\n",
        "  main()"
      ],
      "metadata": {
        "id": "SAA1d7qnz02Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8A2-nkMz05k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}